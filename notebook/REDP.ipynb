{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from catboost import Pool,CatBoostRegressor\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Base path\n",
    "DATA_PATH = \"raw_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5a58b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/leksman/Desktop/my git hub work/end_to_end_Real_Estate_Demand_Predictio/notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec085cb",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# Step 1: Load raw CSV files\n",
    "# Step 2: Merge into a single dataset\n",
    "# Step 3: Preprocess (fill missing values, add prefixes, optimize ints)\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cc5e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
      "/tmp/ipykernel_273933/1034085068.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
      "/tmp/ipykernel_273933/1034085068.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
      "/tmp/ipykernel_273933/1034085068.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"label\"] = data.groupby(\"sector_id\")[\"nht_amount_new_house_transactions\"].shift(lag)\n",
      "/tmp/ipykernel_273933/1034085068.py:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"cs\"] = np.cos((data[\"month_num\"] - 1) / 6 * np.pi)\n",
      "/tmp/ipykernel_273933/1034085068.py:112: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sn\"] = np.sin((data[\"month_num\"] - 1) / 6 * np.pi)\n",
      "/tmp/ipykernel_273933/1034085068.py:113: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"cs6\"] = np.cos((data[\"month_num\"] - 1) / 3 * np.pi)\n",
      "/tmp/ipykernel_273933/1034085068.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sn6\"] = np.sin((data[\"month_num\"] - 1) / 3 * np.pi)\n",
      "/tmp/ipykernel_273933/1034085068.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"cs3\"] = np.cos((data[\"month_num\"] - 1) / 1.5 * np.pi)\n",
      "/tmp/ipykernel_273933/1034085068.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"sn3\"] = np.sin((data[\"month_num\"] - 1) / 1.5 * np.pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train/Test Pools ready!\n",
      "Train size: (6048, 2479)\n",
      "Test size: (288, 2479)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# Setup\n",
    "# -------------------------------\n",
    "os.chdir(\"../\")  # optional, change if needed\n",
    "DATA_PATH = \"raw_data\"\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: add prefixes to columns\n",
    "# -------------------------------\n",
    "def prefix_columns(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"Add a prefix to all columns except sector and month.\"\"\"\n",
    "    rename_map = {col: f\"{prefix}{col}\" for col in df.columns if col not in [\"sector\", \"month\"]}\n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "# -------------------------------\n",
    "# Train Data\n",
    "# -------------------------------\n",
    "ci = (\n",
    "    pd.read_csv(f\"{DATA_PATH}/train/city_indexes.csv\")\n",
    "    .head(6)\n",
    "    .fillna(-1)\n",
    "    .drop(columns=[\"total_fixed_asset_investment_10k\"])\n",
    "    .pipe(prefix_columns, \"ci_\")\n",
    ")\n",
    "\n",
    "csi = pd.read_csv(f\"{DATA_PATH}/train/city_search_index.csv\")\n",
    "\n",
    "sp = pd.read_csv(f\"{DATA_PATH}/train/sector_POI.csv\").fillna(-1).pipe(prefix_columns, \"sp_\")\n",
    "train_lt = pd.read_csv(f\"{DATA_PATH}/train/land_transactions.csv\").pipe(prefix_columns, \"lt_\")\n",
    "train_ltns = pd.read_csv(f\"{DATA_PATH}/train/land_transactions_nearby_sectors.csv\").pipe(prefix_columns, \"ltns_\")\n",
    "train_pht = pd.read_csv(f\"{DATA_PATH}/train/pre_owned_house_transactions.csv\").pipe(prefix_columns, \"pht_\")\n",
    "train_phtns = pd.read_csv(f\"{DATA_PATH}/train/pre_owned_house_transactions_nearby_sectors.csv\").pipe(prefix_columns, \"phtns_\")\n",
    "train_nht = pd.read_csv(f\"{DATA_PATH}/train/new_house_transactions.csv\").pipe(prefix_columns, \"nht_\")\n",
    "train_nhtns = pd.read_csv(f\"{DATA_PATH}/train/new_house_transactions_nearby_sectors.csv\").pipe(prefix_columns, \"nhtns_\")\n",
    "\n",
    "# -------------------------------\n",
    "# Test Data\n",
    "# -------------------------------\n",
    "test = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
    "test[[\"month\", \"sector\"]] = test[\"id\"].str.split(\"_\", expand=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Month mapping\n",
    "# -------------------------------\n",
    "MONTH_CODES = {\n",
    "    \"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4,\n",
    "    \"May\": 5, \"Jun\": 6, \"Jul\": 7, \"Aug\": 8,\n",
    "    \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Base dataset\n",
    "# -------------------------------\n",
    "sectors = pd.DataFrame({\"sector\": train_nht[\"sector\"].unique().tolist() + [\"sector 95\"]})\n",
    "months = pd.DataFrame({\"month\": train_nht[\"month\"].unique()})\n",
    "\n",
    "data = months.merge(sectors, how=\"cross\")\n",
    "data[\"sector_id\"] = data[\"sector\"].str.split(\" \").str[1].astype(\"int16\")\n",
    "data[\"year\"] = data[\"month\"].str.split(\"-\").str[0].astype(\"int16\")\n",
    "data[\"month_num\"] = data[\"month\"].str.split(\"-\").str[1].map(MONTH_CODES).astype(\"int8\")\n",
    "data[\"time\"] = ((data[\"year\"] - 2019) * 12 + data[\"month_num\"] - 1).astype(\"int16\")\n",
    "data = data.sort_values([\"sector_id\", \"time\"])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Join features\n",
    "# -------------------------------\n",
    "data = (\n",
    "    data.merge(train_nht, on=[\"sector\", \"month\"], how=\"left\").fillna(0)\n",
    "        .merge(train_nhtns, on=[\"sector\", \"month\"], how=\"left\").fillna(-1)\n",
    "        .merge(train_pht, on=[\"sector\", \"month\"], how=\"left\").fillna(-1)\n",
    "        .merge(train_phtns, on=[\"sector\", \"month\"], how=\"left\").fillna(-1)\n",
    "        .merge(ci.rename(columns={\"ci_city_indicator_data_year\": \"year\"}), on=\"year\", how=\"left\").fillna(-1)\n",
    "        .merge(sp, on=\"sector\", how=\"left\").fillna(-1)\n",
    "        .merge(train_lt, on=[\"sector\", \"month\"], how=\"left\").fillna(-1)\n",
    "        .merge(train_ltns, on=[\"sector\", \"month\"], how=\"left\").fillna(-1)\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Optimize ints\n",
    "# -------------------------------\n",
    "for col in data.select_dtypes(include=[\"int64\"]).columns:\n",
    "    c_min, c_max = data[col].min(), data[col].max()\n",
    "    if c_min == 0 and c_max == 0:\n",
    "        data.drop(columns=[col], inplace=True)\n",
    "    elif np.iinfo(np.int8).min <= c_min <= np.iinfo(np.int8).max:\n",
    "        data[col] = data[col].astype(\"int8\")\n",
    "    elif np.iinfo(np.int16).min <= c_min <= np.iinfo(np.int16).max:\n",
    "        data[col] = data[col].astype(\"int16\")\n",
    "    elif np.iinfo(np.int32).min <= c_min <= np.iinfo(np.int32).max:\n",
    "        data[col] = data[col].astype(\"int32\")\n",
    "\n",
    "data = data.drop(columns=[\"month\", \"sector\", \"year\"])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Rolling features\n",
    "# -------------------------------\n",
    "data = data.sort_values([\"sector_id\", \"time\"])\n",
    "for col in data.columns[3:]:\n",
    "    for p in [3, 6, 12]:\n",
    "        data[f\"{col}_mean{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).mean())\n",
    "        data[f\"{col}_min{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).min())\n",
    "        data[f\"{col}_max{p}\"] = data.groupby(\"sector_id\")[col].transform(lambda x: x.rolling(p, min_periods=1).max())\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Lag + Cyclical features\n",
    "# -------------------------------\n",
    "lag = 1\n",
    "data[\"label\"] = data.groupby(\"sector_id\")[\"nht_amount_new_house_transactions\"].shift(lag)\n",
    "\n",
    "# cyclical encoding\n",
    "data[\"cs\"] = np.cos((data[\"month_num\"] - 1) / 6 * np.pi)\n",
    "data[\"sn\"] = np.sin((data[\"month_num\"] - 1) / 6 * np.pi)\n",
    "data[\"cs6\"] = np.cos((data[\"month_num\"] - 1) / 3 * np.pi)\n",
    "data[\"sn6\"] = np.sin((data[\"month_num\"] - 1) / 3 * np.pi)\n",
    "data[\"cs3\"] = np.cos((data[\"month_num\"] - 1) / 1.5 * np.pi)\n",
    "data[\"sn3\"] = np.sin((data[\"month_num\"] - 1) / 1.5 * np.pi)\n",
    "\n",
    "data = data.drop(columns=[\"sector_id\"])\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Train/Test Split\n",
    "# -------------------------------\n",
    "cat_features = [\"month_num\"]\n",
    "\n",
    "N_TEST_MONTHS = 3\n",
    "max_time = data[\"time\"].max()\n",
    "border = max_time - N_TEST_MONTHS\n",
    "\n",
    "train_df = data[data[\"time\"] <= border].dropna(subset=[\"label\"])\n",
    "test_df = data[data[\"time\"] > border].dropna(subset=[\"label\"])\n",
    "\n",
    "trainPool = Pool(\n",
    "    data=train_df.drop(columns=[\"label\"]).fillna(-2),\n",
    "    label=train_df[\"label\"],\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "testPool = Pool(\n",
    "    data=test_df.drop(columns=[\"label\"]).fillna(-2),\n",
    "    label=test_df[\"label\"],\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "print(\" Train/Test Pools ready!\")\n",
    "print(\"Train size:\", train_df.shape)\n",
    "print(\"Test size:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caf3d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_num</th>\n",
       "      <th>time</th>\n",
       "      <th>nht_num_new_house_transactions</th>\n",
       "      <th>nht_area_new_house_transactions</th>\n",
       "      <th>nht_price_new_house_transactions</th>\n",
       "      <th>nht_amount_new_house_transactions</th>\n",
       "      <th>nht_area_per_unit_new_house_transactions</th>\n",
       "      <th>nht_total_price_per_unit_new_house_transactions</th>\n",
       "      <th>nht_num_new_house_available_for_sale</th>\n",
       "      <th>nht_area_new_house_available_for_sale</th>\n",
       "      <th>...</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_mean12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_min12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_max12</th>\n",
       "      <th>label</th>\n",
       "      <th>cs</th>\n",
       "      <th>sn</th>\n",
       "      <th>cs6</th>\n",
       "      <th>sn6</th>\n",
       "      <th>cs3</th>\n",
       "      <th>sn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6.048000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6.048000e+03</td>\n",
       "      <td>6.048000e+03</td>\n",
       "      <td>6048.000000</td>\n",
       "      <td>6.048000e+03</td>\n",
       "      <td>6.048000e+03</td>\n",
       "      <td>6.048000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>76.221892</td>\n",
       "      <td>8233.837136</td>\n",
       "      <td>37125.925761</td>\n",
       "      <td>27674.978877</td>\n",
       "      <td>108.778274</td>\n",
       "      <td>522.767811</td>\n",
       "      <td>916.534226</td>\n",
       "      <td>1.061649e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>12504.831276</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>75002.894164</td>\n",
       "      <td>27586.841475</td>\n",
       "      <td>2.168294e-02</td>\n",
       "      <td>3.755596e-02</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>2.749287e-02</td>\n",
       "      <td>-2.784369e-16</td>\n",
       "      <td>7.209226e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.455211</td>\n",
       "      <td>18.185746</td>\n",
       "      <td>154.780902</td>\n",
       "      <td>15982.448830</td>\n",
       "      <td>29066.336594</td>\n",
       "      <td>47084.460640</td>\n",
       "      <td>72.966695</td>\n",
       "      <td>619.300369</td>\n",
       "      <td>1503.110613</td>\n",
       "      <td>1.601766e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>14881.224194</td>\n",
       "      <td>0.413433</td>\n",
       "      <td>84752.286920</td>\n",
       "      <td>47031.837253</td>\n",
       "      <td>7.011951e-01</td>\n",
       "      <td>7.117653e-01</td>\n",
       "      <td>0.706987</td>\n",
       "      <td>7.066305e-01</td>\n",
       "      <td>7.071652e-01</td>\n",
       "      <td>7.071652e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>15793.750000</td>\n",
       "      <td>1559.390000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>173.532500</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9.839250e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1530.742500</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2899.000000</td>\n",
       "      <td>32043.000000</td>\n",
       "      <td>11254.130000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>361.305000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>5.113650e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>7788.834722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53296.000000</td>\n",
       "      <td>11210.960000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8889.250000</td>\n",
       "      <td>52315.250000</td>\n",
       "      <td>32783.045000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>619.425000</td>\n",
       "      <td>1257.000000</td>\n",
       "      <td>1.536355e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>19460.340530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113015.666700</td>\n",
       "      <td>32613.722500</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2669.000000</td>\n",
       "      <td>294430.000000</td>\n",
       "      <td>208288.000000</td>\n",
       "      <td>606407.640000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>7803.600000</td>\n",
       "      <td>12048.000000</td>\n",
       "      <td>1.220617e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>102270.183333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>504823.200000</td>\n",
       "      <td>606407.640000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  2479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         month_num         time  nht_num_new_house_transactions  \\\n",
       "count  6048.000000  6048.000000                     6048.000000   \n",
       "mean      6.333333    32.000000                       76.221892   \n",
       "std       3.455211    18.185746                      154.780902   \n",
       "min       1.000000     1.000000                        0.000000   \n",
       "25%       3.000000    16.000000                        3.000000   \n",
       "50%       6.000000    32.000000                       23.000000   \n",
       "75%       9.000000    48.000000                       79.000000   \n",
       "max      12.000000    63.000000                     2669.000000   \n",
       "\n",
       "       nht_area_new_house_transactions  nht_price_new_house_transactions  \\\n",
       "count                      6048.000000                       6048.000000   \n",
       "mean                       8233.837136                      37125.925761   \n",
       "std                       15982.448830                      29066.336594   \n",
       "min                           0.000000                          0.000000   \n",
       "25%                         441.000000                      15793.750000   \n",
       "50%                        2899.000000                      32043.000000   \n",
       "75%                        8889.250000                      52315.250000   \n",
       "max                      294430.000000                     208288.000000   \n",
       "\n",
       "       nht_amount_new_house_transactions  \\\n",
       "count                        6048.000000   \n",
       "mean                        27674.978877   \n",
       "std                         47084.460640   \n",
       "min                             0.000000   \n",
       "25%                          1559.390000   \n",
       "50%                         11254.130000   \n",
       "75%                         32783.045000   \n",
       "max                        606407.640000   \n",
       "\n",
       "       nht_area_per_unit_new_house_transactions  \\\n",
       "count                               6048.000000   \n",
       "mean                                 108.778274   \n",
       "std                                   72.966695   \n",
       "min                                    0.000000   \n",
       "25%                                   92.000000   \n",
       "50%                                  107.000000   \n",
       "75%                                  128.000000   \n",
       "max                                 2003.000000   \n",
       "\n",
       "       nht_total_price_per_unit_new_house_transactions  \\\n",
       "count                                      6048.000000   \n",
       "mean                                        522.767811   \n",
       "std                                         619.300369   \n",
       "min                                           0.000000   \n",
       "25%                                         173.532500   \n",
       "50%                                         361.305000   \n",
       "75%                                         619.425000   \n",
       "max                                        7803.600000   \n",
       "\n",
       "       nht_num_new_house_available_for_sale  \\\n",
       "count                           6048.000000   \n",
       "mean                             916.534226   \n",
       "std                             1503.110613   \n",
       "min                                0.000000   \n",
       "25%                               67.000000   \n",
       "50%                              381.000000   \n",
       "75%                             1257.000000   \n",
       "max                            12048.000000   \n",
       "\n",
       "       nht_area_new_house_available_for_sale  ...  \\\n",
       "count                           6.048000e+03  ...   \n",
       "mean                            1.061649e+05  ...   \n",
       "std                             1.601766e+05  ...   \n",
       "min                             0.000000e+00  ...   \n",
       "25%                             9.839250e+03  ...   \n",
       "50%                             5.113650e+04  ...   \n",
       "75%                             1.536355e+05  ...   \n",
       "max                             1.220617e+06  ...   \n",
       "\n",
       "       ltns_transaction_amount_nearby_sectors_mean12  \\\n",
       "count                                    6048.000000   \n",
       "mean                                    12504.831276   \n",
       "std                                     14881.224194   \n",
       "min                                        -1.000000   \n",
       "25%                                         0.000000   \n",
       "50%                                      7788.834722   \n",
       "75%                                     19460.340530   \n",
       "max                                    102270.183333   \n",
       "\n",
       "       ltns_transaction_amount_nearby_sectors_min12  \\\n",
       "count                                   6048.000000   \n",
       "mean                                      -0.218750   \n",
       "std                                        0.413433   \n",
       "min                                       -1.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                        0.000000   \n",
       "\n",
       "       ltns_transaction_amount_nearby_sectors_max12          label  \\\n",
       "count                                   6048.000000    6048.000000   \n",
       "mean                                   75002.894164   27586.841475   \n",
       "std                                    84752.286920   47031.837253   \n",
       "min                                       -1.000000       0.000000   \n",
       "25%                                        0.000000    1530.742500   \n",
       "50%                                    53296.000000   11210.960000   \n",
       "75%                                   113015.666700   32613.722500   \n",
       "max                                   504823.200000  606407.640000   \n",
       "\n",
       "                 cs            sn          cs6           sn6           cs3  \\\n",
       "count  6.048000e+03  6.048000e+03  6048.000000  6.048000e+03  6.048000e+03   \n",
       "mean   2.168294e-02  3.755596e-02    -0.015873  2.749287e-02 -2.784369e-16   \n",
       "std    7.011951e-01  7.117653e-01     0.706987  7.066305e-01  7.071652e-01   \n",
       "min   -1.000000e+00 -1.000000e+00    -1.000000 -8.660254e-01 -5.000000e-01   \n",
       "25%   -5.000000e-01 -5.000000e-01    -0.500000 -8.660254e-01 -5.000000e-01   \n",
       "50%    6.123234e-17  1.224647e-16    -0.500000  1.224647e-16 -5.000000e-01   \n",
       "75%    8.660254e-01  8.660254e-01     0.500000  8.660254e-01  1.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00     1.000000  8.660254e-01  1.000000e+00   \n",
       "\n",
       "                sn3  \n",
       "count  6.048000e+03  \n",
       "mean   7.209226e-17  \n",
       "std    7.071652e-01  \n",
       "min   -8.660254e-01  \n",
       "25%   -8.660254e-01  \n",
       "50%   -2.449294e-16  \n",
       "75%    8.660254e-01  \n",
       "max    8.660254e-01  \n",
       "\n",
       "[8 rows x 2479 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b78cda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_num</th>\n",
       "      <th>time</th>\n",
       "      <th>nht_num_new_house_transactions</th>\n",
       "      <th>nht_area_new_house_transactions</th>\n",
       "      <th>nht_price_new_house_transactions</th>\n",
       "      <th>nht_amount_new_house_transactions</th>\n",
       "      <th>nht_area_per_unit_new_house_transactions</th>\n",
       "      <th>nht_total_price_per_unit_new_house_transactions</th>\n",
       "      <th>nht_num_new_house_available_for_sale</th>\n",
       "      <th>nht_area_new_house_available_for_sale</th>\n",
       "      <th>...</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_mean12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_min12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_max12</th>\n",
       "      <th>label</th>\n",
       "      <th>cs</th>\n",
       "      <th>sn</th>\n",
       "      <th>cs6</th>\n",
       "      <th>sn6</th>\n",
       "      <th>cs3</th>\n",
       "      <th>sn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>5.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>80692.0</td>\n",
       "      <td>4229.40</td>\n",
       "      <td>105.0</td>\n",
       "      <td>845.88</td>\n",
       "      <td>476.0</td>\n",
       "      <td>47767.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47012.332812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166591.00000</td>\n",
       "      <td>3622.08</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>75661.0</td>\n",
       "      <td>19445.53</td>\n",
       "      <td>99.0</td>\n",
       "      <td>747.90</td>\n",
       "      <td>452.0</td>\n",
       "      <td>45502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47012.332812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166591.00000</td>\n",
       "      <td>4229.40</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>73385.0</td>\n",
       "      <td>9295.32</td>\n",
       "      <td>97.0</td>\n",
       "      <td>715.02</td>\n",
       "      <td>445.0</td>\n",
       "      <td>44872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42319.864062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166591.00000</td>\n",
       "      <td>19445.53</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.898587e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2824.0</td>\n",
       "      <td>13575.0</td>\n",
       "      <td>3833.23</td>\n",
       "      <td>123.0</td>\n",
       "      <td>166.66</td>\n",
       "      <td>964.0</td>\n",
       "      <td>115482.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3155.24</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>149.0</td>\n",
       "      <td>13445.0</td>\n",
       "      <td>12283.0</td>\n",
       "      <td>16514.18</td>\n",
       "      <td>90.0</td>\n",
       "      <td>110.83</td>\n",
       "      <td>970.0</td>\n",
       "      <td>115797.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3833.23</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.898587e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15124.190477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85408.85714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12522.380953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85408.85714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40079.0</td>\n",
       "      <td>561.19</td>\n",
       "      <td>140.0</td>\n",
       "      <td>561.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12522.380953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85408.85714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.898587e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows  2479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month_num  time  nht_num_new_house_transactions  \\\n",
       "64            5    64                             5.0   \n",
       "65            6    65                            26.0   \n",
       "66            7    66                            13.0   \n",
       "131           5    64                            23.0   \n",
       "132           6    65                           149.0   \n",
       "...         ...   ...                             ...   \n",
       "6363          6    65                             0.0   \n",
       "6364          7    66                             0.0   \n",
       "6429          5    64                             0.0   \n",
       "6430          6    65                             0.0   \n",
       "6431          7    66                             1.0   \n",
       "\n",
       "      nht_area_new_house_transactions  nht_price_new_house_transactions  \\\n",
       "64                              524.0                           80692.0   \n",
       "65                             2570.0                           75661.0   \n",
       "66                             1267.0                           73385.0   \n",
       "131                            2824.0                           13575.0   \n",
       "132                           13445.0                           12283.0   \n",
       "...                               ...                               ...   \n",
       "6363                              0.0                               0.0   \n",
       "6364                              0.0                               0.0   \n",
       "6429                              0.0                               0.0   \n",
       "6430                              0.0                               0.0   \n",
       "6431                            140.0                           40079.0   \n",
       "\n",
       "      nht_amount_new_house_transactions  \\\n",
       "64                              4229.40   \n",
       "65                             19445.53   \n",
       "66                              9295.32   \n",
       "131                             3833.23   \n",
       "132                            16514.18   \n",
       "...                                 ...   \n",
       "6363                               0.00   \n",
       "6364                               0.00   \n",
       "6429                               0.00   \n",
       "6430                               0.00   \n",
       "6431                             561.19   \n",
       "\n",
       "      nht_area_per_unit_new_house_transactions  \\\n",
       "64                                       105.0   \n",
       "65                                        99.0   \n",
       "66                                        97.0   \n",
       "131                                      123.0   \n",
       "132                                       90.0   \n",
       "...                                        ...   \n",
       "6363                                       0.0   \n",
       "6364                                       0.0   \n",
       "6429                                       0.0   \n",
       "6430                                       0.0   \n",
       "6431                                     140.0   \n",
       "\n",
       "      nht_total_price_per_unit_new_house_transactions  \\\n",
       "64                                             845.88   \n",
       "65                                             747.90   \n",
       "66                                             715.02   \n",
       "131                                            166.66   \n",
       "132                                            110.83   \n",
       "...                                               ...   \n",
       "6363                                             0.00   \n",
       "6364                                             0.00   \n",
       "6429                                             0.00   \n",
       "6430                                             0.00   \n",
       "6431                                           561.19   \n",
       "\n",
       "      nht_num_new_house_available_for_sale  \\\n",
       "64                                   476.0   \n",
       "65                                   452.0   \n",
       "66                                   445.0   \n",
       "131                                  964.0   \n",
       "132                                  970.0   \n",
       "...                                    ...   \n",
       "6363                                   0.0   \n",
       "6364                                   0.0   \n",
       "6429                                   0.0   \n",
       "6430                                   0.0   \n",
       "6431                                   1.0   \n",
       "\n",
       "      nht_area_new_house_available_for_sale  ...  \\\n",
       "64                                  47767.0  ...   \n",
       "65                                  45502.0  ...   \n",
       "66                                  44872.0  ...   \n",
       "131                                115482.0  ...   \n",
       "132                                115797.0  ...   \n",
       "...                                     ...  ...   \n",
       "6363                                    0.0  ...   \n",
       "6364                                    0.0  ...   \n",
       "6429                                    0.0  ...   \n",
       "6430                                    0.0  ...   \n",
       "6431                                  195.0  ...   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_mean12  \\\n",
       "64                                     47012.332812   \n",
       "65                                     47012.332812   \n",
       "66                                     42319.864062   \n",
       "131                                        0.000000   \n",
       "132                                        0.000000   \n",
       "...                                             ...   \n",
       "6363                                      -1.000000   \n",
       "6364                                      -1.000000   \n",
       "6429                                   15124.190477   \n",
       "6430                                   12522.380953   \n",
       "6431                                   12522.380953   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_min12  \\\n",
       "64                                             0.0   \n",
       "65                                             0.0   \n",
       "66                                             0.0   \n",
       "131                                            0.0   \n",
       "132                                            0.0   \n",
       "...                                            ...   \n",
       "6363                                          -1.0   \n",
       "6364                                          -1.0   \n",
       "6429                                           0.0   \n",
       "6430                                           0.0   \n",
       "6431                                           0.0   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_max12     label        cs  \\\n",
       "64                                    166591.00000   3622.08 -0.500000   \n",
       "65                                    166591.00000   4229.40 -0.866025   \n",
       "66                                    166591.00000  19445.53 -1.000000   \n",
       "131                                        0.00000   3155.24 -0.500000   \n",
       "132                                        0.00000   3833.23 -0.866025   \n",
       "...                                            ...       ...       ...   \n",
       "6363                                      -1.00000      0.00 -0.866025   \n",
       "6364                                      -1.00000      0.00 -1.000000   \n",
       "6429                                   85408.85714      0.00 -0.500000   \n",
       "6430                                   85408.85714      0.00 -0.866025   \n",
       "6431                                   85408.85714      0.00 -1.000000   \n",
       "\n",
       "                sn  cs6           sn6  cs3           sn3  \n",
       "64    8.660254e-01 -0.5 -8.660254e-01 -0.5  8.660254e-01  \n",
       "65    5.000000e-01  0.5 -8.660254e-01 -0.5 -8.660254e-01  \n",
       "66    1.224647e-16  1.0 -2.449294e-16  1.0 -4.898587e-16  \n",
       "131   8.660254e-01 -0.5 -8.660254e-01 -0.5  8.660254e-01  \n",
       "132   5.000000e-01  0.5 -8.660254e-01 -0.5 -8.660254e-01  \n",
       "...            ...  ...           ...  ...           ...  \n",
       "6363  5.000000e-01  0.5 -8.660254e-01 -0.5 -8.660254e-01  \n",
       "6364  1.224647e-16  1.0 -2.449294e-16  1.0 -4.898587e-16  \n",
       "6429  8.660254e-01 -0.5 -8.660254e-01 -0.5  8.660254e-01  \n",
       "6430  5.000000e-01  0.5 -8.660254e-01 -0.5 -8.660254e-01  \n",
       "6431  1.224647e-16  1.0 -2.449294e-16  1.0 -4.898587e-16  \n",
       "\n",
       "[288 rows x 2479 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b2a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"label\"] != 0]\n",
    "test_df = test_df[test_df[\"label\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7b400e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_num</th>\n",
       "      <th>time</th>\n",
       "      <th>nht_num_new_house_transactions</th>\n",
       "      <th>nht_area_new_house_transactions</th>\n",
       "      <th>nht_price_new_house_transactions</th>\n",
       "      <th>nht_amount_new_house_transactions</th>\n",
       "      <th>nht_area_per_unit_new_house_transactions</th>\n",
       "      <th>nht_total_price_per_unit_new_house_transactions</th>\n",
       "      <th>nht_num_new_house_available_for_sale</th>\n",
       "      <th>nht_area_new_house_available_for_sale</th>\n",
       "      <th>...</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_mean12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_min12</th>\n",
       "      <th>ltns_transaction_amount_nearby_sectors_max12</th>\n",
       "      <th>label</th>\n",
       "      <th>cs</th>\n",
       "      <th>sn</th>\n",
       "      <th>cs6</th>\n",
       "      <th>sn6</th>\n",
       "      <th>cs3</th>\n",
       "      <th>sn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2526.0</td>\n",
       "      <td>34846.0</td>\n",
       "      <td>8802.81</td>\n",
       "      <td>105.0</td>\n",
       "      <td>366.78</td>\n",
       "      <td>158.0</td>\n",
       "      <td>15814.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23167.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46334.50000</td>\n",
       "      <td>13827.14</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6732.0</td>\n",
       "      <td>34589.0</td>\n",
       "      <td>23283.48</td>\n",
       "      <td>99.0</td>\n",
       "      <td>342.40</td>\n",
       "      <td>151.0</td>\n",
       "      <td>14767.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15444.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46334.50000</td>\n",
       "      <td>8802.81</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6935.0</td>\n",
       "      <td>38392.0</td>\n",
       "      <td>26626.68</td>\n",
       "      <td>101.0</td>\n",
       "      <td>385.89</td>\n",
       "      <td>141.0</td>\n",
       "      <td>12936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11583.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46334.50000</td>\n",
       "      <td>23283.48</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>22587.0</td>\n",
       "      <td>8649.42</td>\n",
       "      <td>81.0</td>\n",
       "      <td>184.03</td>\n",
       "      <td>141.0</td>\n",
       "      <td>12936.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9266.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46334.50000</td>\n",
       "      <td>26626.68</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>47216.0</td>\n",
       "      <td>20116.16</td>\n",
       "      <td>104.0</td>\n",
       "      <td>490.64</td>\n",
       "      <td>158.0</td>\n",
       "      <td>16788.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7722.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46334.50000</td>\n",
       "      <td>8649.42</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12733.845237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75230.85714</td>\n",
       "      <td>463.55</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18905.726190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75230.85714</td>\n",
       "      <td>914.99</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.673940e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.347881e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>52694.0</td>\n",
       "      <td>1853.04</td>\n",
       "      <td>176.0</td>\n",
       "      <td>926.52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12636.488095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66996.85714</td>\n",
       "      <td>1274.87</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12636.488095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66996.85714</td>\n",
       "      <td>1853.04</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13943.202381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137215.00000</td>\n",
       "      <td>566.53</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5100 rows  2479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      month_num  time  nht_num_new_house_transactions  \\\n",
       "1             2     1                            24.0   \n",
       "2             3     2                            68.0   \n",
       "3             4     3                            69.0   \n",
       "4             5     4                            47.0   \n",
       "5             6     5                            41.0   \n",
       "...         ...   ...                             ...   \n",
       "6384          8    19                             0.0   \n",
       "6386         10    21                             0.0   \n",
       "6389          1    24                             2.0   \n",
       "6390          2    25                             0.0   \n",
       "6408          8    43                             0.0   \n",
       "\n",
       "      nht_area_new_house_transactions  nht_price_new_house_transactions  \\\n",
       "1                              2526.0                           34846.0   \n",
       "2                              6732.0                           34589.0   \n",
       "3                              6935.0                           38392.0   \n",
       "4                              3829.0                           22587.0   \n",
       "5                              4260.0                           47216.0   \n",
       "...                               ...                               ...   \n",
       "6384                              0.0                               0.0   \n",
       "6386                              0.0                               0.0   \n",
       "6389                            352.0                           52694.0   \n",
       "6390                              0.0                               0.0   \n",
       "6408                              0.0                               0.0   \n",
       "\n",
       "      nht_amount_new_house_transactions  \\\n",
       "1                               8802.81   \n",
       "2                              23283.48   \n",
       "3                              26626.68   \n",
       "4                               8649.42   \n",
       "5                              20116.16   \n",
       "...                                 ...   \n",
       "6384                               0.00   \n",
       "6386                               0.00   \n",
       "6389                            1853.04   \n",
       "6390                               0.00   \n",
       "6408                               0.00   \n",
       "\n",
       "      nht_area_per_unit_new_house_transactions  \\\n",
       "1                                        105.0   \n",
       "2                                         99.0   \n",
       "3                                        101.0   \n",
       "4                                         81.0   \n",
       "5                                        104.0   \n",
       "...                                        ...   \n",
       "6384                                       0.0   \n",
       "6386                                       0.0   \n",
       "6389                                     176.0   \n",
       "6390                                       0.0   \n",
       "6408                                       0.0   \n",
       "\n",
       "      nht_total_price_per_unit_new_house_transactions  \\\n",
       "1                                              366.78   \n",
       "2                                              342.40   \n",
       "3                                              385.89   \n",
       "4                                              184.03   \n",
       "5                                              490.64   \n",
       "...                                               ...   \n",
       "6384                                             0.00   \n",
       "6386                                             0.00   \n",
       "6389                                           926.52   \n",
       "6390                                             0.00   \n",
       "6408                                             0.00   \n",
       "\n",
       "      nht_num_new_house_available_for_sale  \\\n",
       "1                                    158.0   \n",
       "2                                    151.0   \n",
       "3                                    141.0   \n",
       "4                                    141.0   \n",
       "5                                    158.0   \n",
       "...                                    ...   \n",
       "6384                                   0.0   \n",
       "6386                                   0.0   \n",
       "6389                                   6.0   \n",
       "6390                                   0.0   \n",
       "6408                                   0.0   \n",
       "\n",
       "      nht_area_new_house_available_for_sale  ...  \\\n",
       "1                                   15814.0  ...   \n",
       "2                                   14767.0  ...   \n",
       "3                                   12936.0  ...   \n",
       "4                                   12936.0  ...   \n",
       "5                                   16788.0  ...   \n",
       "...                                     ...  ...   \n",
       "6384                                    0.0  ...   \n",
       "6386                                    0.0  ...   \n",
       "6389                                 1277.0  ...   \n",
       "6390                                    0.0  ...   \n",
       "6408                                    0.0  ...   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_mean12  \\\n",
       "1                                      23167.250000   \n",
       "2                                      15444.833333   \n",
       "3                                      11583.625000   \n",
       "4                                       9266.900000   \n",
       "5                                       7722.416667   \n",
       "...                                             ...   \n",
       "6384                                   12733.845237   \n",
       "6386                                   18905.726190   \n",
       "6389                                   12636.488095   \n",
       "6390                                   12636.488095   \n",
       "6408                                   13943.202381   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_min12  \\\n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "5                                              0.0   \n",
       "...                                            ...   \n",
       "6384                                           0.0   \n",
       "6386                                           0.0   \n",
       "6389                                           0.0   \n",
       "6390                                           0.0   \n",
       "6408                                           0.0   \n",
       "\n",
       "      ltns_transaction_amount_nearby_sectors_max12     label            cs  \\\n",
       "1                                      46334.50000  13827.14  8.660254e-01   \n",
       "2                                      46334.50000   8802.81  5.000000e-01   \n",
       "3                                      46334.50000  23283.48  6.123234e-17   \n",
       "4                                      46334.50000  26626.68 -5.000000e-01   \n",
       "5                                      46334.50000   8649.42 -8.660254e-01   \n",
       "...                                            ...       ...           ...   \n",
       "6384                                   75230.85714    463.55 -8.660254e-01   \n",
       "6386                                   75230.85714    914.99 -1.836970e-16   \n",
       "6389                                   66996.85714   1274.87  1.000000e+00   \n",
       "6390                                   66996.85714   1853.04  8.660254e-01   \n",
       "6408                                  137215.00000    566.53 -8.660254e-01   \n",
       "\n",
       "            sn  cs6           sn6  cs3           sn3  \n",
       "1     0.500000  0.5  8.660254e-01 -0.5  8.660254e-01  \n",
       "2     0.866025 -0.5  8.660254e-01 -0.5 -8.660254e-01  \n",
       "3     1.000000 -1.0  1.224647e-16  1.0 -2.449294e-16  \n",
       "4     0.866025 -0.5 -8.660254e-01 -0.5  8.660254e-01  \n",
       "5     0.500000  0.5 -8.660254e-01 -0.5 -8.660254e-01  \n",
       "...        ...  ...           ...  ...           ...  \n",
       "6384 -0.500000  0.5  8.660254e-01 -0.5  8.660254e-01  \n",
       "6386 -1.000000 -1.0  3.673940e-16  1.0 -7.347881e-16  \n",
       "6389  0.000000  1.0  0.000000e+00  1.0  0.000000e+00  \n",
       "6390  0.500000  0.5  8.660254e-01 -0.5  8.660254e-01  \n",
       "6408 -0.500000  0.5  8.660254e-01 -0.5  8.660254e-01  \n",
       "\n",
       "[5100 rows x 2479 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4328edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c96d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67736db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0599cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f4003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "models_and_parameters = {\n",
    "    \"RandomForest\": (\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        {\"model__n_estimators\": [100, 200],\n",
    "         \"model__max_depth\": [5, 10, None]}\n",
    "    ),\n",
    "    \"XGBoost\": (\n",
    "        XGBRegressor(random_state=42, verbosity=0),\n",
    "        {\"model__n_estimators\": [200, 500],\n",
    "         \"model__max_depth\": [4, 6, 8]}\n",
    "    ),\n",
    "    \"LightGBM\": (\n",
    "        LGBMRegressor(random_state=42),\n",
    "        {\"model__n_estimators\": [200, 500],\n",
    "         \"model__num_leaves\": [31, 64]}\n",
    "    ),\n",
    "    \"CatBoost\": (\n",
    "        CatBoostRegressor(verbose=0, random_state=42),\n",
    "        {\"model__iterations\": [500, 1000],\n",
    "         \"model__depth\": [6, 8]}\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ba5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cc309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running GridSearch for RandomForest...\n",
      " RandomForest best params: {'model__n_estimators': 200, 'model__max_depth': None}\n",
      " RandomForest CV MSE: 406679006.0713\n",
      "\n",
      " Running GridSearch for XGBoost...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, (model, params) in models_and_parameters.items():\n",
    "    print(f\"\\n Running GridSearch for {name}...\")\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    grid = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=params,   # same dict\n",
    "    n_iter=5,                     # try only 5 random combinations\n",
    "    cv=3,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    best_score = -grid.best_score_  # convert to positive MSE\n",
    "    \n",
    "    print(f\" {name} best params: {grid.best_params_}\")\n",
    "    print(f\" {name} CV MSE: {best_score:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": grid.best_params_,\n",
    "        \"CV MSE\": best_score\n",
    "    })\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Compare models\n",
    "# -------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tran_pred =  best_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.984735235389213)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(r2_score(y_true=y_train,y_pred=y_tran_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b350c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9efff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1125fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82755eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
